{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GOLDEN_Sentiment_Analysis.txt",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzofSSMl00rF",
        "colab_type": "text"
      },
      "source": [
        "## Twitter US Airlines Sentiment \n",
        "Challenge: To apply a supervised or semi-supervised ULMFiT model to Twitter US Airlines Sentiment\n",
        "\n",
        "This problem is a straightforward language analysis problem, and a good exercise to learn how to filter noisy Data. Often text data that we will analyse will have lots of unnecessary characters and information which is not relevant to the goal of the modeling exercise. This problem reminds us to always view data from that perspective.\n",
        "\n",
        "Text classification can be carried out as unsupervised or supervised.\n",
        "In this case, clearly we are going to use supervised learning as we are using the labels in the columns while training the model.\n",
        "\n",
        "In case of unsupervised model, we would just provide it the various reviews and ask the model to learn.\n",
        "\n",
        "I could not find a SOTA reference for this challenge, although it is a very popular problem on various forums at Kaggle, Medium etc\n",
        "Most of the references though are using Machine Learning Algorithms such as decision trees, Naive Bayes or Logistic Regression etc. \n",
        "However this challenge asked us to use Fast.ai's AW-LSTM Model.\n",
        "\n",
        "There are no visualizations for this , also there is not much need for feature engineering for this Deep Learning problem. FE was usually applicable for mathematical data or data which can be operated upon. \n",
        "\n",
        "We have used TextClassificationInterpretation to interpret the task.\n",
        "\n",
        "### As regards modeling techniques, we train the model in two steps-\n",
        "### 1. We first fine-tune a language model, which is previously trained on Wikipedia text, on the twitter dataset.\n",
        "### 2. We use this language model as an encoder (word embeddings) and train a classifier model.\n",
        "\n",
        "The AWD-LSTM Model is a basic model, unlike the Transformer Model \n",
        "\n",
        "We solve a sentiment analysis problem using the fastai library.\n",
        "\n",
        "This Twitter data was scraped from February of 2015 and contributors were asked to first classify tweets. It contains 14640 texts with label of postive, negative or neutral sentiment. The maximum size of a text is 280 characters which is the limit in Twitter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otWdpVs7qBtO",
        "colab_type": "text"
      },
      "source": [
        "# Check the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L92gkCjOiZtG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d33274c6-846c-40d8-c3f4-14e02eb95bb9"
      },
      "source": [
        "# Check the GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 19 12:06:17 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpBpVpREYn6v",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0W_QfPUYn6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3HsdoBGYn63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fastai library for NLP\n",
        "from fastai.text import *\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymXMMQabYn66",
        "colab_type": "text"
      },
      "source": [
        "# Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3jvUrBMgbgX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "c7abaf67-4585-427c-8469-9730377734bb"
      },
      "source": [
        "# Mount google drive to access its files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy22cK3RYn6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Provide path to the csv file\n",
        "path = 'drive/My Drive/Fellowship.ai/Sentiment Analysis/Tweets.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGnlcGO6Yn7F",
        "colab_type": "text"
      },
      "source": [
        "Print the original csv file to understand the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-NZ2Zs4Yn7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "d7b9f2ca-437b-49e0-f8c4-68dd4edbece9"
      },
      "source": [
        "# Read the csv file into a pandas dataframe\n",
        "df = pd.read_csv(path)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_7ZiURVVmMp",
        "colab_type": "text"
      },
      "source": [
        "### Since we only need the text and sentiment from the csv file, we copy these two columns to a separate pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7VMFzGHifMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.DataFrame({'label':df['airline_sentiment'], 'text':df['text']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8nAkRA_VznG",
        "colab_type": "text"
      },
      "source": [
        "We save the dataframe file as a csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dGvUDevYn7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the file as csv without the index column\n",
        "df2.to_csv('data.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llERrctskDwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "119e4986-8a58-4b33-a772-bd03e6e536e3"
      },
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text\n",
              "0   neutral                @VirginAmerica What @dhepburn said.\n",
              "1  positive  @VirginAmerica plus you've added commercials t...\n",
              "2   neutral  @VirginAmerica I didn't today... Must mean I n...\n",
              "3  negative  @VirginAmerica it's really aggressive to blast...\n",
              "4  negative  @VirginAmerica and it's a really big bad thing..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o3aF82I30aU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0073b486-a935-462f-812d-8cef724f5b83"
      },
      "source": [
        "# Number of tweets\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14640"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGJC1UWpWJW3",
        "colab_type": "text"
      },
      "source": [
        "#Clean Data\n",
        "This dataset has a column named text which contains the tweets from customers for a particular airline and a label which tells whether the tweet has a positive, neutral or negative sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTYr8OnvYn78",
        "colab_type": "text"
      },
      "source": [
        "# Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EVzbNo7Xlh1",
        "colab_type": "text"
      },
      "source": [
        "We first have to convert the words into numbers. This is done in two steps-\n",
        "1. Tokenization - We split the entire text using spaces, punctuations, special symbols etc. as delimiters.\n",
        "2. Numericalization - We convert these tokens to a dictionary format where the key is the word and value is the number associated to it.\n",
        "\n",
        "The fastai library will automatically launch the tokenization process with the spacy tokenizer and a few default rules for pre and post-processing before numericalizing the tokens.\n",
        "\n",
        "### When we call TextLMDataBunch function of Fast.ai, all this is done behind the scenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dLxdoqYffSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8738cc3c-7695-4584-9def-df5ed8cbd132"
      },
      "source": [
        "path = ''\n",
        "data_lm = TextLMDataBunch.from_csv(path, 'data.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gstTLgdbbWnq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "When we display a batch, there are no y_labels as we only need the text to build the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jSVQb_gfmBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "c031077f-f10c-41ea-9a58-d1b18f482305"
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>. xxmaj thank you xxbos @americanair welcome anyone who works in those conditions deserves a thank you even though i am other side of # xxmaj atlantic lol xx xxbos @united xxmaj good evening , xxup ua . xxmaj can you assist with an issue via xxup dm ? xxbos @usairways thanks for getting us on ur plane . xxmaj awesome flight attendant who is making us smile after difficult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>'s y all corporate number bc y all are not trying to accommodate me at all ! ! ! xxbos @jetblue xxmaj love your airline ... hate your website . xxmaj just tried to book 2 tickets ( 1 w miles , 1 w / out ) . xxmaj absolute joke . xxmaj needs a lot of work ! xxbos @united 129 thousand fans of @jedediahbila are asking you to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>@usairways i submitted refund request b4 1st flight 2 days ago . xxmaj is that all i need 2 do ? xxbos @united thanks for the reply . xxmaj to clarify , the airfare is similar to your likely intended xxunk group . xxmaj the $ 3 beer charge , however , is not xxbos @united we were not given the option of using our xxmaj united xxunk in a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>simply amazing . xxmaj xxunk for miles . xxmaj thank u for my upgrade tomorrow for xxunk are spending a lot of time together next few weeks ! xxbos @jetblue i did not report the updated info - do n't know how to reach them without a super long wait on hold at your main number . xxbos @southwestair # destinationdragons xxmaj any word on winners of contest ? xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>they do n't want to honor my flight . xxbos @usairways xxmaj thank you , @usairways ! xxmaj your fare to from xxup dtw to xxup dca was much lower than @delta and @southwestair ! xxmaj thank you ! xxmaj you won me over ! xxbos @southwestair and thx for not responding xxbos @jetblue xxmaj only middle seats . xxup sfo - &gt; xxup bos . xxmaj not fun .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPc9XZf8welE",
        "colab_type": "text"
      },
      "source": [
        "There are quite a few strange tokens starting with xx. These are special FastAI tokens that have the following meanings:\n",
        "\n",
        "    xxunk: Token used instead of unknown words (words not found in the vocabulary).\n",
        "    xxbos: Beginning of a text.\n",
        "    xxfld: Represents separate parts of your document (several columns in a dataframe) like headline, body, summary, etc.\n",
        "    xxmaj: Indicates that the next word starts with a capital, e.g. “House” will be tokenized as “xxmaj house”.\n",
        "    xxup: Indicates that next word is written in all caps, e.g. “WHY” will be tokenized as “xxup why ”.\n",
        "    xxrep: Token indicates that a character is repeated n times, e.g. if you have  10 $ in a row it will be tokenized as “xxrep 10 $” (in general “xxrep n  {char}”)\n",
        "    xxwrep: Indicates that a word is repeated n times.\n",
        "    xxpad : Token used as padding (so every text has the same length)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Hq6LeVHEaC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "f622ed22-d029-4ac6-db69-4c4fa812ea91"
      },
      "source": [
        "# Print the first 30 items in the vocabulary\n",
        "data_lm.vocab.itos[:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xxunk',\n",
              " 'xxpad',\n",
              " 'xxbos',\n",
              " 'xxeos',\n",
              " 'xxfld',\n",
              " 'xxmaj',\n",
              " 'xxup',\n",
              " 'xxrep',\n",
              " 'xxwrep',\n",
              " '.',\n",
              " 'to',\n",
              " 'i',\n",
              " 'the',\n",
              " '!',\n",
              " 'a',\n",
              " '?',\n",
              " 'you',\n",
              " '/',\n",
              " ',',\n",
              " 'for',\n",
              " 'flight',\n",
              " '@united',\n",
              " 'on',\n",
              " 'and',\n",
              " '#',\n",
              " 'my',\n",
              " '@usairways',\n",
              " '@americanair',\n",
              " 'is',\n",
              " 'in']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x04CWt3cHuqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "c8ad6443-11d7-4d10-f70e-c4c6fca1afaa"
      },
      "source": [
        "# Sanity print check the data in language model\n",
        "data_lm.train_ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelList (11711 items)\n",
              "x: LMTextList\n",
              "xxbos @usairways it 's not like i 'm trying to leave earlier just for fun . i do n't want to get stuck in xxup dc if we have bad weather in xxup rdu .,xxbos @united xxmaj will do ! xxmaj thanks !,xxbos @jetblue unfortunately i was so xxunk and rushed , i did n't get the name , but will provide a xxunk in my xxunk email . xxmaj thank you,xxbos @americanair welcome anyone who works in those conditions deserves a thank you even though i am other side of # xxmaj atlantic lol xx,xxbos @united xxmaj good evening , xxup ua . xxmaj can you assist with an issue via xxup dm ?\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUHYCp4QHSwh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7fae1696-f945-48d2-f52f-0aafab6b875a"
      },
      "source": [
        "# Print the Numericalization data i.e. numbers associated with the words\n",
        "data_lm.train_ds[0][0].data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,  26,  31,  44,  41, 119,  11,  82, 141,  10, 355, 419,  64,  19, 965,   9,  11,  47,  34, 188,  10,  49,\n",
              "       246,  29,   6, 632,  87,  51,  37, 238, 150,  29,   6, 820,   9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL-yD8-zbkzU",
        "colab_type": "text"
      },
      "source": [
        "Finally, we will load this data into a learner object with a model having pretrained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKvw_0XW4wx5",
        "colab_type": "text"
      },
      "source": [
        "## AWD LSTM \n",
        "\n",
        "As such, AWD-LSTM has been dominating the state-of-the-art language modeling. A lot of top research papers on word-level models incorporate AWD-LSTMs. And it has shown great results on character-level models as well.\n",
        "\n",
        "Since we are using a small dataset with a max size of 280 characters in a sample, a regularized and optimized LSTM model should be more than sufficient to achieve good results. It serves the purpose to form and remember the context by having long short-term memory, earlier missing in simple RNNs.\n",
        "\n",
        "The fast.ai's universal language model ULMfit uses Stephen Merity’s Wikitext 103 dataset, which contains a pre-processed large subset of English Wikipedia. This helps us leverage the power of word embeddings, which further helps the model to understand and associate a text to a particular sentiment.\n",
        "\n",
        "### Fast.ai's ULMFit Model uses the AWD-LSTM architecture and applies the appropriate weights using the language_model_learner wrapper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWWcESCEYn8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7425f178-4489-4ccb-e56a-0bff6688e228"
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1wP48ShYn8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "b5d26027-464c-4029-c684-11be6eb01653"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      50.00% [1/2 00:06<00:06]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.388725</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='34' class='' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      53.12% [34/64 00:03<00:02 9.0072]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NmhVE3J0ci2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ceb2146b-1939-44dc-e19b-3894349cc31c"
      },
      "source": [
        "# plot the range\n",
        "learn.recorder.plot(skip_end=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJP4HHPWYn8f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "a6aee619-e13f-4af1-89fd-51da0d75c44e"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.721487</td>\n",
              "      <td>4.074032</td>\n",
              "      <td>0.249895</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqFvV4ZlYn8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('fit_head')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeTofS3UYn8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.load('fit_head');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYvSZYu4Yn8n",
        "colab_type": "text"
      },
      "source": [
        "Unfreeze the model and train further for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXZ6eEk_Yn8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set every layer group to trainable\n",
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR8oh8z83IIA",
        "colab_type": "text"
      },
      "source": [
        "### Learning rate is critical.\n",
        "LR >> Validation Loss too High\n",
        "\n",
        "LR << Error Rate improves slowly, long time to train (refit) \n",
        "\n",
        "Epochs >> Overfit, ER too high\n",
        "\n",
        "Epochs << Training Loss more than Validation Loss, ER improves (refit)\n",
        "\n",
        "We use the fastai learning rate finder to glean a good starting point for a learning rate. Consider the point where the loss just begins to taper (slope)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwDgmIaXYn8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "18ab9ee3-8ee5-4896-ce96-70be5120bfd5"
      },
      "source": [
        "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.002950</td>\n",
              "      <td>3.897451</td>\n",
              "      <td>0.274068</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.861327</td>\n",
              "      <td>3.762355</td>\n",
              "      <td>0.289076</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.706820</td>\n",
              "      <td>3.695446</td>\n",
              "      <td>0.297610</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.483981</td>\n",
              "      <td>3.664596</td>\n",
              "      <td>0.301064</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.237294</td>\n",
              "      <td>3.684798</td>\n",
              "      <td>0.300433</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.962875</td>\n",
              "      <td>3.743228</td>\n",
              "      <td>0.298004</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.700261</td>\n",
              "      <td>3.800833</td>\n",
              "      <td>0.295890</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.485629</td>\n",
              "      <td>3.876554</td>\n",
              "      <td>0.293015</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.336885</td>\n",
              "      <td>3.915147</td>\n",
              "      <td>0.291912</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.254760</td>\n",
              "      <td>3.926724</td>\n",
              "      <td>0.291268</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFTxFN2mfBN_",
        "colab_type": "text"
      },
      "source": [
        "We get an accuracy of almost 29% which means our model is able to predict the next word in a sentence with a probability of 29%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-048ul3Yn81",
        "colab_type": "text"
      },
      "source": [
        "We do a sanity check and see how good our model is by seeing what it predicts after a few given words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSGDHx8jYn84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"I liked this airline because\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZmWPmRJYn88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "4b7400bb-10ed-4b53-900c-a0b1c8e7e486"
      },
      "source": [
        "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I liked this airline because they are helpful and provide small services in my business . Too bad i love you xxbos @united i 'm flying home tonight , but i 've been stuck in Chicago with no gate agent yet , ca\n",
            "I liked this airline because of your planes ! Awesome ! Thank you ! xxbos @united i 'm talking about my Cancelled Flighted flight and the phone line . What gives ? xxbos @jetblue Thank you for the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ast5edo7Yn8_",
        "colab_type": "text"
      },
      "source": [
        "# Language Model Inference\n",
        "### When a given a simple sentence with just 5 words, the model is able to complete the sentence to the required number of words. \n",
        "\n",
        "### This sentence prediction seems grammatically very accurate with a good use of different parts of speech at the right places. However, the context does not make much sense right now.\n",
        "\n",
        "### We leverage this power to train our classifier model quite easily, as the model now just has to learn to associate a text to a particular label.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov1bkQHqYn9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We save the model as well as its encoder, as this part is responsible for guessing the next word.\n",
        "learn.save_encoder('fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_BSN3HaYn9C",
        "colab_type": "text"
      },
      "source": [
        "# Classifier Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb1r0oYAYn9D",
        "colab_type": "text"
      },
      "source": [
        "We create a new data object that grabs the labelled data and keeps those labels. We also use our vocabulary from the language model as we'll be loading the encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zly9xn_3jlOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0d721b5d-b73a-4d43-d70d-f3f21dd0b23d"
      },
      "source": [
        "data_clas = TextClasDataBunch.from_csv(path, 'data.csv', vocab=data_lm.vocab) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJKjQa7VYn9U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "5c8d363e-b3e0-4db5-c2f1-53e2c4d80f86"
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos @united xxmaj hi have a question re future xxmaj flight xxmaj booking xxmaj problems . xxup dub - xxup jac 29 / 9 xxup jac - xxup lax 8 / 10 xxup lax - xxup dub 13 / 10 . i 'm * xxup g. xxmaj what is checked bag xxunk for xxup jac - xxup lax ?</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos @southwestair xxmaj the xxmaj fact xxmaj that u xxmaj see xxmaj black xxmaj history xxmaj month 12 xxmaj months a xxmaj year xxmaj is xxmaj xxunk ! xxmaj we xxup will xxup be xxmaj an xxmaj xxunk xxmaj base xxmaj for xxmaj corp. xxmaj like u xxmaj in xxmaj future !</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos @jetblue i ❤ ️ xxmaj jetblue but i was on flt xxunk from fll to sfo . xxunk off was over 1 hr xxmaj late xxmaj flight , div to phx &amp; &amp; got in 2 hrs xxmaj late xxmaj flight . xxmaj what will be done ?</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos @united - xxup seriously it 's 2015 ? ! ? ! xxup no wifi on a 5hr flight from xxup cle - xxup sfo # xxunk . xxmaj you 're the xxup only airline w / out wifi ... and pls no ' xxunk ' xxup bs .</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos @usairways yes , i am as well . * * xxup five * * xxup hours xxup on xxup hold , xxup folks . xxmaj can you xxup please tell me if this is typical ? ! xxmaj trying to be understanding here .</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3dxFtY94V78",
        "colab_type": "text"
      },
      "source": [
        "#Create Text Classification Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlDkwL4MYn9g",
        "colab_type": "text"
      },
      "source": [
        "With our language model ready and the encoder saved, we can now create a text classification model, load in the encoder we saved before, and train the network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUI9biDvYn9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "069e12d8-6c4c-4d60-d5ad-4ef1338255dc"
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.3)\n",
        "\n",
        "learn.load_encoder('fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (11711 items)\n",
              "x: TextList\n",
              "xxbos @united okay . xxmaj thanks .,xxbos @jetblue i will . i love flying with you all . xxmaj great service .,xxbos @southwestair xxmaj love xxmaj southwest . xxmaj you guys have been good to me ! http : / / t.co / xxunk,xxbos @united xxmaj never can get a flight out on time . 4 hour delay earlier another hour delay on my connecting flight . xxmaj makes 10 straight delays,xxbos @usairways @jack_kairys ( 2 / 2 ) and another sent him to the wrong line ... oh and the kiosks were n't working ! # thanks\n",
              "y: CategoryList\n",
              "neutral,positive,positive,negative,negative\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (2929 items)\n",
              "x: TextList\n",
              "xxbos @united i flew back w other company since xxmaj united did nt have an earlier flight,xxbos @united tried to book a flight xxup iah - xxup xxunk departing 3 / 31 / 15 returning 4 / 17 / 15 you are advertising 9 flights for $ 1051 that ca n't be book !,xxbos @virginamerica requested window seat and confirmed window but got stuck in middle seat . xxmaj not a good way to treat silver member 😒,xxbos @jetblue xxunk well here we go,xxbos @jetblue they say they have no update . i do n't work i do n't get paid . xxmaj jet blue has my money but no flight . xxmaj xxunk !\n",
              "y: CategoryList\n",
              "negative,negative,negative,positive,negative\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(5872, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(5872, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f7b5e0cabf8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (11711 items)\n",
              "x: TextList\n",
              "xxbos @united okay . xxmaj thanks .,xxbos @jetblue i will . i love flying with you all . xxmaj great service .,xxbos @southwestair xxmaj love xxmaj southwest . xxmaj you guys have been good to me ! http : / / t.co / xxunk,xxbos @united xxmaj never can get a flight out on time . 4 hour delay earlier another hour delay on my connecting flight . xxmaj makes 10 straight delays,xxbos @usairways @jack_kairys ( 2 / 2 ) and another sent him to the wrong line ... oh and the kiosks were n't working ! # thanks\n",
              "y: CategoryList\n",
              "neutral,positive,positive,negative,negative\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (2929 items)\n",
              "x: TextList\n",
              "xxbos @united i flew back w other company since xxmaj united did nt have an earlier flight,xxbos @united tried to book a flight xxup iah - xxup xxunk departing 3 / 31 / 15 returning 4 / 17 / 15 you are advertising 9 flights for $ 1051 that ca n't be book !,xxbos @virginamerica requested window seat and confirmed window but got stuck in middle seat . xxmaj not a good way to treat silver member 😒,xxbos @jetblue xxunk well here we go,xxbos @jetblue they say they have no update . i do n't work i do n't get paid . xxmaj jet blue has my money but no flight . xxmaj xxunk !\n",
              "y: CategoryList\n",
              "negative,negative,negative,positive,negative\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(5872, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(5872, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f7b5e0cabf8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(5872, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(5872, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(5872, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(5872, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.12, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q0nFopbYn9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "3cc622c0-2736-46f9-f8a2-c43ad0cfcce9"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='91' class='' max='182' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      50.00% [91/182 00:02<00:02 1.5154]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X7Y9KwVYn9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "4a306fe6-c2ec-4cd8-fe2f-e83bac9be0bc"
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg6ZTlgUYn9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "af0c5c4a-c1c3-4d90-972b-4fea3a8b9fad"
      },
      "source": [
        "learn.fit_one_cycle(2, 1e-2, moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.667757</td>\n",
              "      <td>0.523368</td>\n",
              "      <td>0.790714</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.582983</td>\n",
              "      <td>0.534837</td>\n",
              "      <td>0.794128</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ASn8exA0e-q",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tuning model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxZmrqaCd4lE",
        "colab_type": "text"
      },
      "source": [
        "We unfreeze the model layer by layer for better fine-tuning.\n",
        "\n",
        "*Note*: Here I tried several options and the default Fast.ai Divisor 10, but I also found a Hyper Parameter divisor which seems to have worked well for others in the community. I tried the same and it worked well in this case too, hence I decided to use 2.6**4 as my divisor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5VNZYm-Yn9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "f0ff2a31-21c0-487e-8e3c-1a92ff2ceae1"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(2, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.590327</td>\n",
              "      <td>0.509854</td>\n",
              "      <td>0.803687</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.498216</td>\n",
              "      <td>0.476655</td>\n",
              "      <td>0.816661</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzpLx66_Yn96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "bb05ba4a-9116-495d-ab0f-d736cbd4c7e1"
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(2, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.491309</td>\n",
              "      <td>0.473672</td>\n",
              "      <td>0.820075</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.339011</td>\n",
              "      <td>0.509069</td>\n",
              "      <td>0.824172</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTPu7yH6eWja",
        "colab_type": "text"
      },
      "source": [
        "We unfreeze the model completely and train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxWMYdXTYn-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ee73d160-2028-4371-88dc-c1154d5ec73d"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(5, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.262461</td>\n",
              "      <td>0.519975</td>\n",
              "      <td>0.827245</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.227206</td>\n",
              "      <td>0.556426</td>\n",
              "      <td>0.811540</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.164258</td>\n",
              "      <td>0.602784</td>\n",
              "      <td>0.817685</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.141637</td>\n",
              "      <td>0.620743</td>\n",
              "      <td>0.818027</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.126593</td>\n",
              "      <td>0.621162</td>\n",
              "      <td>0.818368</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y46K8t9LfQUq",
        "colab_type": "text"
      },
      "source": [
        "## Final Accuracy - **82.7%** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVlaFKlk7GDy",
        "colab_type": "text"
      },
      "source": [
        "As such, we can improve the model by playing with the hyper parameters. However, I decided to stop here I observed that the Accuracy was falling after more epochs. We also see the Error Rate increases as the epochs increase, which could suggest overfit, however, in this case it does not change but remains fairly constant. This means overfitting is not really an issue, keeing in mind the inbuilt regularization of the AWD-LSTM model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx3wWWkjGI2V",
        "colab_type": "text"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG_tAsGN_3fd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b8abdec8-ab24-4b87-d327-1b760ee89f27"
      },
      "source": [
        "interp = TextClassificationInterpretation.from_learner(learn) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lC-vj_MAE2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "be93b095-3765-4dd1-fd66-94e8faaea5cd"
      },
      "source": [
        "for i in range(5):\n",
        "  x = interp.show_intrinsic_attention(df.loc[i])\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"font-family: monospace;\"><span title=\"0.117\" style=\"background-color: rgba(220, 58, 43, 0.5);\">xxbos</span> <span title=\"0.203\" style=\"background-color: rgba(244, 109, 67, 0.5);\">xxunk</span> <span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">@virginamerica</span> <span title=\"0.138\" style=\"background-color: rgba(225, 70, 49, 0.5);\">xxmaj</span> <span title=\"0.557\" style=\"background-color: rgba(233, 245, 161, 0.5);\">what</span> <span title=\"0.509\" style=\"background-color: rgba(251, 253, 185, 0.5);\">xxunk</span> <span title=\"0.547\" style=\"background-color: rgba(236, 247, 165, 0.5);\">said</span> <span title=\"0.223\" style=\"background-color: rgba(246, 124, 74, 0.5);\">.</span></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"font-family: monospace;\"><span title=\"0.120\" style=\"background-color: rgba(220, 58, 43, 0.5);\">xxbos</span> <span title=\"0.333\" style=\"background-color: rgba(253, 190, 110, 0.5);\">positive</span> <span title=\"0.846\" style=\"background-color: rgba(66, 171, 90, 0.5);\">@virginamerica</span> <span title=\"0.671\" style=\"background-color: rgba(181, 223, 115, 0.5);\">plus</span> <span title=\"0.338\" style=\"background-color: rgba(253, 192, 112, 0.5);\">you</span> <span title=\"0.695\" style=\"background-color: rgba(169, 218, 107, 0.5);\">&#x27;ve</span> <span title=\"0.542\" style=\"background-color: rgba(239, 248, 169, 0.5);\">added</span> <span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">commercials</span> <span title=\"0.174\" style=\"background-color: rgba(236, 92, 59, 0.5);\">to</span> <span title=\"0.109\" style=\"background-color: rgba(216, 51, 40, 0.5);\">the</span> <span title=\"0.209\" style=\"background-color: rgba(244, 114, 69, 0.5);\">experience</span> <span title=\"0.261\" style=\"background-color: rgba(249, 147, 84, 0.5);\">...</span> <span title=\"0.297\" style=\"background-color: rgba(252, 172, 96, 0.5);\">xxunk</span> <span title=\"0.130\" style=\"background-color: rgba(223, 65, 47, 0.5);\">.</span></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"font-family: monospace;\"><span title=\"0.134\" style=\"background-color: rgba(224, 68, 48, 0.5);\">xxbos</span> <span title=\"0.213\" style=\"background-color: rgba(245, 116, 70, 0.5);\">xxunk</span> <span title=\"0.956\" style=\"background-color: rgba(11, 124, 65, 0.5);\">@virginamerica</span> <span title=\"0.280\" style=\"background-color: rgba(251, 159, 90, 0.5);\">i</span> <span title=\"0.531\" style=\"background-color: rgba(243, 250, 175, 0.5);\">did</span> <span title=\"0.579\" style=\"background-color: rgba(224, 242, 149, 0.5);\">n&#x27;t</span> <span title=\"0.366\" style=\"background-color: rgba(253, 206, 124, 0.5);\">today</span> <span title=\"0.393\" style=\"background-color: rgba(253, 220, 135, 0.5);\">...</span> <span title=\"0.246\" style=\"background-color: rgba(248, 139, 81, 0.5);\">xxmaj</span> <span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">must</span> <span title=\"0.607\" style=\"background-color: rgba(213, 237, 136, 0.5);\">mean</span> <span title=\"0.289\" style=\"background-color: rgba(252, 167, 94, 0.5);\">i</span> <span title=\"0.630\" style=\"background-color: rgba(201, 232, 128, 0.5);\">need</span> <span title=\"0.241\" style=\"background-color: rgba(247, 134, 78, 0.5);\">to</span> <span title=\"0.791\" style=\"background-color: rgba(107, 191, 99, 0.5);\">take</span> <span title=\"0.488\" style=\"background-color: rgba(254, 250, 183, 0.5);\">another</span> <span title=\"0.925\" style=\"background-color: rgba(19, 139, 73, 0.5);\">trip</span> <span title=\"0.936\" style=\"background-color: rgba(16, 134, 70, 0.5);\">!</span></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"font-family: monospace;\"><span title=\"0.079\" style=\"background-color: rgba(204, 37, 38, 0.5);\">xxbos</span> <span title=\"0.235\" style=\"background-color: rgba(247, 131, 77, 0.5);\">negative</span> <span title=\"0.560\" style=\"background-color: rgba(231, 245, 159, 0.5);\">@virginamerica</span> <span title=\"0.186\" style=\"background-color: rgba(239, 99, 62, 0.5);\">it</span> <span title=\"0.173\" style=\"background-color: rgba(236, 92, 59, 0.5);\">&#x27;s</span> <span title=\"0.447\" style=\"background-color: rgba(254, 238, 163, 0.5);\">really</span> <span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">aggressive</span> <span title=\"0.204\" style=\"background-color: rgba(244, 111, 68, 0.5);\">to</span> <span title=\"0.971\" style=\"background-color: rgba(7, 117, 61, 0.5);\">blast</span> <span title=\"0.193\" style=\"background-color: rgba(241, 104, 64, 0.5);\">xxunk</span> <span title=\"0.136\" style=\"background-color: rgba(224, 68, 48, 0.5);\">&quot;</span> <span title=\"0.489\" style=\"background-color: rgba(254, 251, 185, 0.5);\">entertainment</span> <span title=\"0.121\" style=\"background-color: rgba(221, 61, 45, 0.5);\">&quot;</span> <span title=\"0.153\" style=\"background-color: rgba(230, 80, 53, 0.5);\">in</span> <span title=\"0.257\" style=\"background-color: rgba(248, 144, 83, 0.5);\">your</span> <span title=\"0.457\" style=\"background-color: rgba(254, 242, 169, 0.5);\">guests</span> <span title=\"0.184\" style=\"background-color: rgba(239, 99, 62, 0.5);\">&#x27;</span> <span title=\"0.419\" style=\"background-color: rgba(254, 230, 149, 0.5);\">faces</span> <span title=\"0.364\" style=\"background-color: rgba(253, 206, 124, 0.5);\">&amp;</span> <span title=\"0.123\" style=\"background-color: rgba(221, 61, 45, 0.5);\">&amp;</span> <span title=\"0.174\" style=\"background-color: rgba(236, 92, 59, 0.5);\">they</span> <span title=\"0.217\" style=\"background-color: rgba(245, 119, 71, 0.5);\">have</span> <span title=\"0.553\" style=\"background-color: rgba(234, 246, 163, 0.5);\">little</span> <span title=\"0.842\" style=\"background-color: rgba(69, 173, 90, 0.5);\">recourse</span></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"font-family: monospace;\"><span title=\"0.139\" style=\"background-color: rgba(225, 70, 49, 0.5);\">xxbos</span> <span title=\"0.388\" style=\"background-color: rgba(253, 218, 134, 0.5);\">negative</span> <span title=\"0.889\" style=\"background-color: rgba(33, 155, 81, 0.5);\">@virginamerica</span> <span title=\"0.193\" style=\"background-color: rgba(241, 104, 64, 0.5);\">and</span> <span title=\"0.295\" style=\"background-color: rgba(252, 170, 95, 0.5);\">it</span> <span title=\"0.325\" style=\"background-color: rgba(253, 186, 107, 0.5);\">&#x27;s</span> <span title=\"0.349\" style=\"background-color: rgba(253, 198, 117, 0.5);\">a</span> <span title=\"0.987\" style=\"background-color: rgba(3, 109, 57, 0.5);\">really</span> <span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">big</span> <span title=\"0.725\" style=\"background-color: rgba(149, 209, 104, 0.5);\">bad</span> <span title=\"0.603\" style=\"background-color: rgba(215, 238, 137, 0.5);\">thing</span> <span title=\"0.502\" style=\"background-color: rgba(254, 254, 189, 0.5);\">about</span> <span title=\"0.222\" style=\"background-color: rgba(245, 121, 72, 0.5);\">it</span></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYk3kMzEC4fn",
        "colab_type": "text"
      },
      "source": [
        "The colors show how the model is interpreting the ingest data. The model assigns weights ranging from -1 to 1 corresponding to different colors.\n",
        "e.g. Model assigns similar context to all text having same color, and gives relative importance to the darker shaded text when interpreting data \n",
        "\n",
        "Green - The attention colors show that nouns and adjectives like '@virginamerica', 'commericial', 'big', 'trip' have similar weights. It also captures relevant some short verbs like 'did not', 'blast', 'take' in lighter colors.\n",
        "\n",
        "Red - The fastai special tokens have similar weights. Also, some verbs like 'have', 'it is' and smaller words like 'your', 'and, 'it' take lighter colors.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC5KeJNjeg-x",
        "colab_type": "text"
      },
      "source": [
        "# Model Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAtbsRKgeaSY",
        "colab_type": "text"
      },
      "source": [
        "We run the model prediction on some sample tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muisau1bGymz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ae4930d1-67e9-40bf-ef7f-13e74cc4888f"
      },
      "source": [
        "data_clas.classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative', 'neutral', 'positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj0bQ24kYn-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dd3198e4-61f5-44c1-df4a-110dbb915b97"
      },
      "source": [
        "# Positive Tweet\n",
        "learn.predict(\"@Virgin I really loved that airline, it was awesome!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(2), tensor(2), tensor([7.7929e-05, 1.0337e-07, 9.9992e-01]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_YEOpjBYn-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c512aa81-6d03-472a-cf54-6cea58163aba"
      },
      "source": [
        "# Negative Tweet\n",
        "learn.predict(\"@Toronto I do not enjoy taking flights from this airport\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(0), tensor(0), tensor([9.9996e-01, 2.9250e-05, 9.1083e-06]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}